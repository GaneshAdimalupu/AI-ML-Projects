{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82df592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b16e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10 # Output layer will be in the form of a number in [0,9]\n",
    "input_shape = (28, 28, 1) # Input image is in a 28 X 28 pixel format\n",
    "\n",
    "# Loading test/train data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241cc885",
   "metadata": {},
   "source": [
    "We are importing an image where each pixel is in grayscale.\n",
    "\n",
    "This is represented in a range of 0 to 255, 0 being Black and 255 being white\n",
    "\n",
    "For easier representation, we divide each element by 255 to scale down to [0,1]\n",
    "\n",
    "![Matrix visualised](./images/MNIST-Matrix.png \"28x28 Matrix with scaled down integers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ba69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# To ensure shape of matrix is 28 X 28\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c81d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape), # setting input shape as 28 X 28 X 1 (2d input)\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ddaae",
   "metadata": {},
   "source": [
    "Explaining the previous cell\n",
    "\n",
    "First we define the input size to the model.\n",
    "\n",
    "Then we define the kernel size and the activation function to be used, while relu is most used, you may also use tanh\n",
    "\n",
    "![RelU vs TanH](./images/relu.jpeg \"RelU vs TanH\")\n",
    "\n",
    "Then we define the pooling size, in our case 2X2. this basically selects the max value in a 2x2 matrix\n",
    "\n",
    "Then we repeat the process, as we have chosen 2 conv layers, after which we flatten them.\n",
    "\n",
    "Then in order to reduce the risk of overfitting we set the dropout to 0.5 i.e. some neurons will be randomly turned on and off to add entropy\n",
    "\n",
    "After which we use softmax to give the output in the form of a probablity array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f13fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Gives a summary of the designed model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7fb602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 12s 27ms/step - loss: 1.1590 - accuracy: 0.8529 - val_loss: 0.0803 - val_accuracy: 0.9767\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 11s 27ms/step - loss: 0.1766 - accuracy: 0.9473 - val_loss: 0.0553 - val_accuracy: 0.9843\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 12s 27ms/step - loss: 0.1255 - accuracy: 0.9618 - val_loss: 0.0516 - val_accuracy: 0.9857\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 12s 28ms/step - loss: 0.1062 - accuracy: 0.9675 - val_loss: 0.0440 - val_accuracy: 0.9867\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 12s 27ms/step - loss: 0.0920 - accuracy: 0.9717 - val_loss: 0.0449 - val_accuracy: 0.9868\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 11s 27ms/step - loss: 0.0861 - accuracy: 0.9739 - val_loss: 0.0441 - val_accuracy: 0.9882\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0762 - accuracy: 0.9764 - val_loss: 0.0373 - val_accuracy: 0.9895\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 12s 28ms/step - loss: 0.0713 - accuracy: 0.9782 - val_loss: 0.0336 - val_accuracy: 0.9913\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 13s 30ms/step - loss: 0.0669 - accuracy: 0.9791 - val_loss: 0.0361 - val_accuracy: 0.9908\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 12s 27ms/step - loss: 0.0669 - accuracy: 0.9789 - val_loss: 0.0364 - val_accuracy: 0.9903\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0623 - accuracy: 0.9803 - val_loss: 0.0372 - val_accuracy: 0.9915\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 12s 27ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.0356 - val_accuracy: 0.9895\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 12s 27ms/step - loss: 0.0577 - accuracy: 0.9813 - val_loss: 0.0409 - val_accuracy: 0.9893\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0570 - accuracy: 0.9826 - val_loss: 0.0396 - val_accuracy: 0.9897\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0549 - accuracy: 0.9828 - val_loss: 0.0360 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f3aedc2e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we train the model\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ece05f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.034038905054330826\n",
      "Test accuracy: 0.9901000261306763\n"
     ]
    }
   ],
   "source": [
    "# Testing with test data\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8aa08b4109e02faef70797796bfd5fb313790bd5a534ff08957d24923938621"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
